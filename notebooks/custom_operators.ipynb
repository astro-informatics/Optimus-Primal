{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "<center><img src=\"../docs/assets/animated_logo.png\" align=\"center\" height=\"100\" width=\"100\">\n",
        "\n",
        "# [`Optimus-Primal`](https://github.com/astro-informatics/Optimus-Primal) - __Custom Operator__ Interactive Tutorial\n",
        "---\n",
        "\n",
        "In this interactive tutorial we demonstrate basic usage of `optimusprimal` for a 2-dimensional noisy inpainting problem with a custom measurement operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "How to run a basic 2D unconstrained proximal primal-dual solver, this time with a custom measurement operator $\\Phi$. \n",
        "We consider the canonical problem $y = \\Phi x + n$ where $n \\sim \\mathcal{N}$, and $\\Phi$ encodes the \n",
        "forward-model of the problem. This inverse problem can be solved via the unconstrained optimisation \n",
        "\n",
        "$$\n",
        "\\min_x [ ||(\\Phi x-y)/\\sigma||^2_2 + \\lambda ||\\Psi^{\\dagger} x||_1 ]\n",
        "$$\n",
        "\n",
        "where $x \\in \\mathbb{R}^2$ is an a priori ground truth 2D signal, $y \\in \\mathbb{R}^2$ \n",
        "are simulated noisy observations, and $\\lambda$ is the regularisation parameter which acts as \n",
        "a Lagrangian multiplier, balancing between data-fidelity and prior information. Before we begin, we \n",
        "need to import ``optimusprimal`` and some example specific packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.misc as misc \n",
        "from scipy.signal import resample\n",
        "\n",
        "import optimusprimal.primal_dual as primal_dual\n",
        "import optimusprimal.grad_operators as grad_operators\n",
        "import optimusprimal.linear_operators as linear_operators\n",
        "import optimusprimal.prox_operators as prox_operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to define some heuristics for the solver, these include:\n",
        "\n",
        "      - tol: convergence criteria for the iterations\n",
        "      - iter: maximum number of iterations\n",
        "      - update_iter: iterations between logging iteration diagnostics\n",
        "      - record_iters: whether to record the full diagnostic information\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "options = {\"tol\": 1e-5, \"iter\": 5000, \"update_iter\": 50, \"record_iters\": False}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this point lets set up the forward-model of the problem, which we will \n",
        "encode to the measurement operator $\\Phi$.\n",
        "For this problem lets consider the forward model which is a masking in \n",
        "pixel-space, in which case this inverse problem becomes a noisy \n",
        "in-painting problem!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class custom_phi(linear_operators.LinearOperator):\n",
        "    \"\"\"A custom linear operator e.g. a custom measurement operator\"\"\"\n",
        "\n",
        "    def __init__(self, dim, masking):\n",
        "        \"\"\"Initialise the operator with any necessary parameters\"\"\"\n",
        "        self.dim = dim\n",
        "\n",
        "        # Generate a random mask\n",
        "        mask = np.full(dim**2, False)\n",
        "        mask[:int(masking*dim**2)] = True\n",
        "        np.random.shuffle(mask)\n",
        "        self.mask = mask\n",
        "    \n",
        "    def dir_op(self, x):\n",
        "        \"\"\"Forward linear operator\"\"\"\n",
        "        return x.flatten('C')[self.mask]\n",
        "    \n",
        "    def adj_op(self, x):\n",
        "        \"\"\"Adjoint linear operator\"\"\"\n",
        "        f = np.zeros(self.dim**2)\n",
        "        f[self.mask] = x\n",
        "        return f.reshape(self.dim, self.dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we simulate a noisy in-painting setting by contaminating simulated \n",
        "observations $y$, of a known\n",
        "signal $x$, with some Gaussianly distributed noise $n$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ISNR = 30.0                                            # Input signal to noise ratio\n",
        "sigma = 10 ** (-ISNR / 20.0)                           # Noise standard deviation\n",
        "reg_param = 4.5                                        # Regularisation parameter\n",
        "res = 256                                              # Resolution we want to work with\n",
        "masking = 0.5                                          # Fraction of the observations to use\n",
        "phi = custom_phi(dim=res, masking=masking)             # Custom forward-model of the problem\n",
        "\n",
        "x = misc.ascent()                                      # Scipy's ascent benchmark image\n",
        "for i in range(2):\n",
        "    x = resample(x, axis=i, num=res)\n",
        "x /= np.nanmax(x)                                      # Normalise image\n",
        "\n",
        "y = phi.dir_op(x)                                      # Simulated observations y\n",
        "n = np.random.normal(0, sigma, y.shape)                # Random Gaussian noise\n",
        "y += n                                                 # Contaminate y with noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the unconstrained problem with Gaussian noise the data-fidelity constraint\n",
        "is given by the gradient of the $\\ell_2$-norm. Here we set up a gradient operator\n",
        "corresponding to a gradient of the $\\ell_2$-norm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = grad_operators.l2_norm(sigma, y, phi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We regularise this inverse problem by adopting a wavelet sparsity $\\ell_1$-norm prior.\n",
        "To do this we first define what wavelets we wish to use, in this case a\n",
        "combination of Daubechies family wavelets, and which levels to consider.\n",
        "Any combination of wavelet families available by the [`PyWavelet`](https://tinyurl.com/5n7wzpmb) \n",
        "package may be selected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wav = [\"db1\", \"db4\"]                                     # Wavelet dictionaries to combine\n",
        "levels = 4                                               # Wavelet levels to consider [1-6]\n",
        "psi = linear_operators.dictionary(wav, levels, x.shape)  # Wavelet linear operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we construct the $\\ell_1$-norm proximal operator which we pass the wavelets\n",
        "($\\Psi$) as a dictionary in which to compute the $\\ell_1$-norm. We also add an\n",
        "additional reality constraint f for good measure, as we know a priori our\n",
        "signal $x$ is real.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h = prox_operators.l1_norm(np.max(np.abs(psi.dir_op(phi.adj_op(y)))) * reg_param, psi)\n",
        "f = prox_operators.real_prox()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we run the optimisation...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Note that phi_adj_op(y) is a dirty first estimate. In practice one may wish to begin the optimisation from a better first guess!\n",
        "best_estimate, diagnostics = primal_dual.FBPD(phi.adj_op(y), options, g, f, h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...and plot the results!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def eval_snr(x, x_est):\n",
        "    if np.array_equal(x, x_est):\n",
        "        return 0\n",
        "    num = np.sqrt(np.sum(np.abs(x) ** 2))\n",
        "    den = np.sqrt(np.sum(np.abs(x - x_est) ** 2))\n",
        "    return round(20*np.log10(num/den), 2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=[10, 5])\n",
        "\n",
        "titles = [\"Data\", \"Truth\", \"Reconstruction\"]\n",
        "est = [phi.adj_op(y), x, best_estimate]\n",
        "\n",
        "for i in range(3):\n",
        "    axs[i].imshow(est[i], cmap=\"magma\", vmax=np.max(x), vmin=np.min(x))\n",
        "    axs[i].set_title(titles[i], fontsize=14)\n",
        "    axs[i].set_xlabel(\"SNR: {}dB,\".format(eval_snr(x, est[i])), fontsize=12)\n",
        "\n",
        "    plt.setp(axs[i].get_xticklabels(), visible=False)\n",
        "    plt.setp(axs[i].get_yticklabels(), visible=False)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
